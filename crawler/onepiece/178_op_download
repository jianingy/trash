#!/usr/bin/env python2.6
# -*- coding: utf-8 -*-
# author: jianingy.yang@gmail.com

import time, os, sys
import re, logging, urllib, urllib2, mechanize, simplejson

BASE_URL = "http://manhua.178.com/h/haizeiwang.shtml"
IMAGE_URL = "http://manhua.178.com/imgs/"

def download_image(root, url, episode, slide):

  try:

    logging.info("start downloading slide %s at %s" % (episode, url))
    data = urllib2.urlopen(url).read()

    image = "%s/%s/%02d.png" % (root, episode, slide)
    logging.info("start saving image at %s" % image)
    dirname = os.path.dirname(image)
    if not os.path.isdir(dirname):
      os.makedirs(dirname)

    assert os.path.isdir(dirname)

    file(image, "w+").write(data)
    logging.info("image saved successfully")

    return image

  except urllib2.HTTPError:
    logging.info("image saved failed")
    return None

def extract_image_address(episode):
  br = mechanize.Browser()
  br.open(BASE_URL)
  response = br.follow_link(text_regex="%sËØù" % episode)
  assert br.viewing_html()
  prefix = "var pages = "
  pages = filter(lambda x: x.startswith(prefix), response.read().splitlines())
  assert(pages)
  pages = pages[0][len(prefix):].lstrip("'").rstrip("';")
  return map(lambda x: urllib.quote(x.encode("UTF-8")), simplejson.loads(str(pages)))

if __name__ == "__main__":
  logging.basicConfig(level=logging.DEBUG, output=sys.stderr)
  episode = sys.argv[1]
  root = "."
  html = "<html><body>\n"
  for i, rel in enumerate(extract_image_address(episode)):
    image = download_image(root, IMAGE_URL + rel, episode, i + 1)
    html = html + "<img src=\"%s\">\n<br>\n" % image
  html = html + "</body></html>"
  file("%s/%s/index.html" % (root, episode), "w+").write(html)
